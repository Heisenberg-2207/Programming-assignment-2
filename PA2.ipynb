{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from collections import namedtuple, deque\n",
    "import torch.optim as optim\n",
    "import datetime\n",
    "import gym\n",
    "#from gym.wrappers.record_video import RecordVideo\n",
    "import glob\n",
    "import io\n",
    "import base64\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import HTML\n",
    "from IPython import display as ipythondisplay\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make('Acrobot-v1')\n",
    "state_shape = env.observation_space.shape[0]\n",
    "no_of_actions = env.action_space.n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "### Q Network & Some 'hyperparameters'\n",
    "\n",
    "QNetwork1:\n",
    "Input Layer - 6 nodes (State Shape) \\\n",
    "Hidden Layer 1 - 128 nodes \\\n",
    "Hidden Layer 2 - 64 nodes \\\n",
    "Output Layer - 3 nodes (Action Space) \\\n",
    "Optimizer - zero_grad()\n",
    "'''\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "'''\n",
    "Bunch of Hyper parameters (Which you might have to tune later)\n",
    "'''\n",
    "BUFFER_SIZE = int(1e5)  # replay buffer size\n",
    "BATCH_SIZE = 64         # minibatch size\n",
    "GAMMA = 0.99            # discount factor\n",
    "LR = 5e-4               # learning rate\n",
    "UPDATE_EVERY = 20       # how often to update the network (When Q target is present)\n",
    "\n",
    "\n",
    "class QNetwork1(nn.Module):\n",
    "\n",
    "    def __init__(self, state_size, action_size,type=1, fc1_units=128, fc2_units=64):\n",
    "        \"\"\"Initialize parameters and build model.\n",
    "        Params\n",
    "        ======\n",
    "            state_size (int): Dimension of each state\n",
    "            action_size (int): Dimension of each action\n",
    "            seed (int): Random seed\n",
    "            fc1_units (int): Number of nodes in first hidden layer\n",
    "            fc2_units (int): Number of nodes in second hidden layer\n",
    "        \"\"\"\n",
    "        super(QNetwork1, self).__init__()\n",
    "        self.fc1 = nn.Linear(state_size, fc1_units)\n",
    "        self.fc2 = nn.Linear(fc1_units, fc2_units)\n",
    "        self.advantage_fc = nn.Linear(fc2_units, action_size)\n",
    "        self.value_fc = nn.Linear(fc2_units, 1)\n",
    "        self.type =type\n",
    "\n",
    "    def forward(self, state):\n",
    "        \"\"\"Build a network that maps state -> action values.\"\"\"\n",
    "        x = F.relu(self.fc1(state))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        advantage = self.advantage_fc(x)\n",
    "        value = self.value_fc(x)\n",
    "        if self.type ==1:\n",
    "            q_values = value + (advantage - advantage.mean(dim = 1, keepdim = True))\n",
    "        else:\n",
    "            q_values = value + (advantage - torch.max(advantage))\n",
    "        return q_values\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import torch\n",
    "import numpy as np\n",
    "from collections import deque, namedtuple\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "class ReplayBuffer:\n",
    "    \"\"\"Fixed-size buffer to store experience tuples.\"\"\"\n",
    "\n",
    "    def __init__(self, action_size, buffer_size, batch_size, seed):\n",
    "        \"\"\"Initialize a ReplayBuffer object.\n",
    "\n",
    "        Params\n",
    "        ======\n",
    "            action_size (int): dimension of each action\n",
    "            buffer_size (int): maximum size of buffer\n",
    "            batch_size (int): size of each training batch\n",
    "            seed (int): random seed\n",
    "        \"\"\"\n",
    "        self.action_size = action_size\n",
    "        self.memory = deque(maxlen=buffer_size)\n",
    "        self.batch_size = batch_size\n",
    "        self.experience = namedtuple(\"Experience\", field_names=[\"state\", \"action\", \"reward\", \"next_state\", \"done\"])\n",
    "        self.seed = random.seed(seed)\n",
    "\n",
    "    def add(self, state, action, reward, next_state, done):\n",
    "        \"\"\"Add a new experience to memory.\"\"\"\n",
    "        e = self.experience(state, action, reward, next_state, done)\n",
    "        self.memory.append(e)\n",
    "\n",
    "    def sample(self):\n",
    "        \"\"\"Randomly sample a batch of experiences from memory.\"\"\"\n",
    "        experiences = random.sample(self.memory, k=self.batch_size)\n",
    "\n",
    "        states = torch.from_numpy(np.vstack([e.state for e in experiences if e is not None])).float().to(device)\n",
    "        actions = torch.from_numpy(np.vstack([e.action for e in experiences if e is not None])).long().to(device)\n",
    "        rewards = torch.from_numpy(np.vstack([e.reward for e in experiences if e is not None])).float().to(device)\n",
    "        next_states = torch.from_numpy(np.vstack([e.next_state for e in experiences if e is not None])).float().to(device)\n",
    "        dones = torch.from_numpy(np.vstack([e.done for e in experiences if e is not None]).astype(np.uint8)).float().to(device)\n",
    "\n",
    "        return (states, actions, rewards, next_states, dones)\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Return the current size of internal memory.\"\"\"\n",
    "        return len(self.memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.special import softmax\n",
    "class TutorialAgent():\n",
    "\n",
    "    def __init__(self, state_size, action_size,type, seed):\n",
    "\n",
    "        ''' Agent Environment Interaction '''\n",
    "        self.state_size = state_size\n",
    "        self.action_size = action_size\n",
    "        self.seed = random.seed(seed)\n",
    "\n",
    "        ''' Q-Network '''\n",
    "        self.qnetwork_local = QNetwork1(state_size, action_size,type).to(device)\n",
    "        self.qnetwork_target = QNetwork1(state_size, action_size,type).to(device)\n",
    "        self.optimizer = optim.Adam(self.qnetwork_local.parameters(), lr=LR)\n",
    "\n",
    "        ''' Replay memory '''\n",
    "        self.memory = ReplayBuffer(action_size, BUFFER_SIZE, BATCH_SIZE, seed)\n",
    "\n",
    "        ''' Initialize time step (for updating every UPDATE_EVERY steps)           -Needed for Q Targets '''\n",
    "        self.t_step = 0\n",
    "\n",
    "    def step(self, state, action, reward, next_state, done):\n",
    "\n",
    "        ''' Save experience in replay memory '''\n",
    "        self.memory.add(state, action, reward, next_state, done)\n",
    "\n",
    "        ''' If enough samples are available in memory, get random subset and learn '''\n",
    "        if len(self.memory) >= BATCH_SIZE:\n",
    "            experiences = self.memory.sample()\n",
    "            self.learn(experiences, GAMMA)\n",
    "\n",
    "        \"\"\" +Q TARGETS PRESENT \"\"\"\n",
    "        ''' Updating the Network every 'UPDATE_EVERY' steps taken '''\n",
    "        self.t_step = (self.t_step + 1) % UPDATE_EVERY\n",
    "        if self.t_step == 0:\n",
    "\n",
    "            self.qnetwork_target.load_state_dict(self.qnetwork_local.state_dict())\n",
    "\n",
    "    #adding arguments to decide hypermeter(tau for softmax and eps for ep-greedy) and what policy to use\n",
    "    def act(self, state, policy, hyp=0.):\n",
    "\n",
    "        state = torch.from_numpy(state).float().unsqueeze(0).to(device)\n",
    "        self.qnetwork_local.eval()\n",
    "        with torch.no_grad():\n",
    "            action_values = self.qnetwork_local(state)\n",
    "        self.qnetwork_local.train()\n",
    "\n",
    "\n",
    "        ''' Epsilon-greedy action selection (Already Present) '''\n",
    "        if(policy == \"eps greedy\"):\n",
    "          if random.random() > hyp:\n",
    "              return np.argmax(action_values.cpu().data.numpy())\n",
    "          else:\n",
    "              return random.choice(np.arange(self.action_size))\n",
    "\n",
    "\n",
    "        ''' Softmax action selection '''\n",
    "        if(policy == \"softmax\"):\n",
    "          action_probs = softmax(action_values.cpu().data.numpy().flatten() / hyp)\n",
    "          return np.random.choice(np.arange(self.action_size), p=action_probs)\n",
    "\n",
    "    def learn(self, experiences, gamma):\n",
    "        \"\"\" +E EXPERIENCE REPLAY PRESENT \"\"\"\n",
    "        states, actions, rewards, next_states, dones = experiences\n",
    "\n",
    "        ''' Get max predicted Q values (for next states) from target model'''\n",
    "        Q_targets_next = self.qnetwork_target(next_states).detach().max(1)[0].unsqueeze(1)\n",
    "\n",
    "        ''' Compute Q targets for current states '''\n",
    "        Q_targets = rewards + (gamma * Q_targets_next * (1 - dones))\n",
    "\n",
    "        ''' Get expected Q values from local model '''\n",
    "        Q_expected = self.qnetwork_local(states).gather(1, actions)\n",
    "\n",
    "        ''' Compute loss '''\n",
    "        loss = F.mse_loss(Q_expected, Q_targets)\n",
    "\n",
    "        ''' Minimize the loss '''\n",
    "        self.optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "\n",
    "        ''' Gradiant Clipping '''\n",
    "        \"\"\" +T TRUNCATION PRESENT \"\"\"\n",
    "        for param in self.qnetwork_local.parameters():\n",
    "            param.grad.data.clamp_(-1, 1)\n",
    "\n",
    "        self.optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\anike\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\gym\\utils\\passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)\n",
      "  if not isinstance(terminated, (bool, np.bool8)):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 12\tAverage Score: -263.50"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 48\u001b[0m\n\u001b[0;32m     45\u001b[0m begin_time \u001b[38;5;241m=\u001b[39m datetime\u001b[38;5;241m.\u001b[39mdatetime\u001b[38;5;241m.\u001b[39mnow()\n\u001b[0;32m     47\u001b[0m agent \u001b[38;5;241m=\u001b[39m TutorialAgent(state_size\u001b[38;5;241m=\u001b[39mstate_shape,action_size \u001b[38;5;241m=\u001b[39m action_shape,\u001b[38;5;28mtype\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, seed \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m---> 48\u001b[0m \u001b[43mdqn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpolicy\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msoftmax\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     50\u001b[0m time_taken \u001b[38;5;241m=\u001b[39m datetime\u001b[38;5;241m.\u001b[39mdatetime\u001b[38;5;241m.\u001b[39mnow() \u001b[38;5;241m-\u001b[39m begin_time\n\u001b[0;32m     52\u001b[0m \u001b[38;5;66;03m#evaluation criteras\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[15], line 22\u001b[0m, in \u001b[0;36mdqn\u001b[1;34m(policy, n_episodes, max_t, hyp_start, hyp_end, hyp_decay)\u001b[0m\n\u001b[0;32m     20\u001b[0m action \u001b[38;5;241m=\u001b[39m agent\u001b[38;5;241m.\u001b[39mact(state, policy, hyp \u001b[38;5;241m=\u001b[39m hyp)\n\u001b[0;32m     21\u001b[0m next_state, reward, done, _, _ \u001b[38;5;241m=\u001b[39m env\u001b[38;5;241m.\u001b[39mstep(action)\n\u001b[1;32m---> 22\u001b[0m \u001b[43magent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreward\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnext_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdone\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     23\u001b[0m state \u001b[38;5;241m=\u001b[39m next_state\n\u001b[0;32m     24\u001b[0m score \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m reward\n",
      "Cell \u001b[1;32mIn[14], line 30\u001b[0m, in \u001b[0;36mTutorialAgent.step\u001b[1;34m(self, state, action, reward, next_state, done)\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmemory) \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m BATCH_SIZE:\n\u001b[0;32m     29\u001b[0m     experiences \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmemory\u001b[38;5;241m.\u001b[39msample()\n\u001b[1;32m---> 30\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlearn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexperiences\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mGAMMA\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\" +Q TARGETS PRESENT \"\"\"\u001b[39;00m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m''' Updating the Network every 'UPDATE_EVERY' steps taken '''\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[14], line 87\u001b[0m, in \u001b[0;36mTutorialAgent.learn\u001b[1;34m(self, experiences, gamma)\u001b[0m\n\u001b[0;32m     84\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m param \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mqnetwork_local\u001b[38;5;241m.\u001b[39mparameters():\n\u001b[0;32m     85\u001b[0m     param\u001b[38;5;241m.\u001b[39mgrad\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mclamp_(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m---> 87\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\anike\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\optim\\optimizer.py:385\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    380\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    381\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m    382\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    383\u001b[0m             )\n\u001b[1;32m--> 385\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    386\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer_step_code()\n\u001b[0;32m    388\u001b[0m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\anike\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\optim\\optimizer.py:76\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     74\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefaults[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdifferentiable\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m     75\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n\u001b[1;32m---> 76\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     77\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     78\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n",
      "File \u001b[1;32mc:\\Users\\anike\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\optim\\adam.py:166\u001b[0m, in \u001b[0;36mAdam.step\u001b[1;34m(self, closure)\u001b[0m\n\u001b[0;32m    155\u001b[0m     beta1, beta2 \u001b[38;5;241m=\u001b[39m group[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbetas\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m    157\u001b[0m     has_complex \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_group(\n\u001b[0;32m    158\u001b[0m         group,\n\u001b[0;32m    159\u001b[0m         params_with_grad,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    163\u001b[0m         max_exp_avg_sqs,\n\u001b[0;32m    164\u001b[0m         state_steps)\n\u001b[1;32m--> 166\u001b[0m     \u001b[43madam\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    167\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams_with_grad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    168\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    169\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    170\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    171\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    172\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    173\u001b[0m \u001b[43m        \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mamsgrad\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    174\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhas_complex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    175\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    176\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    177\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    178\u001b[0m \u001b[43m        \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mweight_decay\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    179\u001b[0m \u001b[43m        \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43meps\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    180\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmaximize\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    181\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforeach\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mforeach\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    182\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcapturable\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    183\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdifferentiable\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    184\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfused\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfused\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    185\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgrad_scale\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    186\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfound_inf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    187\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    189\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "File \u001b[1;32mc:\\Users\\anike\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\optim\\adam.py:316\u001b[0m, in \u001b[0;36madam\u001b[1;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, has_complex, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[0;32m    313\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    314\u001b[0m     func \u001b[38;5;241m=\u001b[39m _single_tensor_adam\n\u001b[1;32m--> 316\u001b[0m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    317\u001b[0m \u001b[43m     \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    318\u001b[0m \u001b[43m     \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    319\u001b[0m \u001b[43m     \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    320\u001b[0m \u001b[43m     \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    321\u001b[0m \u001b[43m     \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    322\u001b[0m \u001b[43m     \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mamsgrad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    323\u001b[0m \u001b[43m     \u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhas_complex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    324\u001b[0m \u001b[43m     \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    325\u001b[0m \u001b[43m     \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    326\u001b[0m \u001b[43m     \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    327\u001b[0m \u001b[43m     \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweight_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    328\u001b[0m \u001b[43m     \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    329\u001b[0m \u001b[43m     \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaximize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    330\u001b[0m \u001b[43m     \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcapturable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    331\u001b[0m \u001b[43m     \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdifferentiable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    332\u001b[0m \u001b[43m     \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgrad_scale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    333\u001b[0m \u001b[43m     \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfound_inf\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\anike\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\optim\\adam.py:382\u001b[0m, in \u001b[0;36m_single_tensor_adam\u001b[1;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, has_complex, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable)\u001b[0m\n\u001b[0;32m    379\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m weight_decay \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    380\u001b[0m     grad \u001b[38;5;241m=\u001b[39m grad\u001b[38;5;241m.\u001b[39madd(param, alpha\u001b[38;5;241m=\u001b[39mweight_decay)\n\u001b[1;32m--> 382\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_complex\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparam\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m    383\u001b[0m     grad \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mview_as_real(grad)\n\u001b[0;32m    384\u001b[0m     exp_avg \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mview_as_real(exp_avg)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# @title Task 1c\n",
    "''' Defining DQN Algorithm '''\n",
    "\n",
    "state_shape = env.observation_space.shape[0]\n",
    "action_shape = env.action_space.n\n",
    "\n",
    "#pass policy to dqn, default is softmax\n",
    "def dqn(policy, n_episodes=10000, max_t=1000, hyp_start=1.0, hyp_end=0.01, hyp_decay=0.995):\n",
    "\n",
    "    scores_window = deque(maxlen=100)\n",
    "    ''' last 100 scores for checking if the avg is more than 195 '''\n",
    "\n",
    "    hyp = hyp_start\n",
    "    ''' initialize epsilon '''\n",
    "\n",
    "    for i_episode in range(1, n_episodes+1):\n",
    "        state,_ = env.reset()\n",
    "        score = 0\n",
    "        for t in range(max_t):\n",
    "            action = agent.act(state, policy, hyp = hyp)\n",
    "            next_state, reward, done, _, _ = env.step(action)\n",
    "            agent.step(state, action, reward, next_state, done)\n",
    "            state = next_state\n",
    "            score += reward\n",
    "            if done:\n",
    "                break\n",
    "\n",
    "        scores_window.append(score)\n",
    "\n",
    "        hyp = max(hyp_end, hyp_decay*hyp)\n",
    "        ''' decrease epsilon '''\n",
    "\n",
    "        print('\\rEpisode {}\\tAverage Score: {:.2f}'.format(i_episode, np.mean(scores_window)), end=\"\")\n",
    "        avg_rewards.append(np.mean(scores_window))\n",
    "        if i_episode % 100 == 0:\n",
    "           print('\\rEpisode {}\\tAverage Score: {:.2f}'.format(i_episode, np.mean(scores_window)))\n",
    "        if np.mean(scores_window)>=-100:\n",
    "           print('\\nEnvironment solved in {:d} episodes!\\tAverage Score: {:.2f}'.format(i_episode, np.mean(scores_window)))\n",
    "           break\n",
    "    return True\n",
    "\n",
    "''' Trial run to check if algorithm runs and saves the data '''\n",
    "\n",
    "avg_rewards = []\n",
    "begin_time = datetime.datetime.now()\n",
    "\n",
    "agent = TutorialAgent(state_size=state_shape,action_size = action_shape,type=1, seed = 0)\n",
    "dqn(policy = \"softmax\")\n",
    "\n",
    "time_taken = datetime.datetime.now() - begin_time\n",
    "\n",
    "#evaluation criteras\n",
    "print(time_taken)\n",
    "plt.plot( np.arange(0, len(avg_rewards), 1), avg_rewards)\n",
    "plt.title(\"Average Reward vs episodes, policy: eps greedy\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 100\tAverage Score: -175.60\n",
      "Episode 200\tAverage Score: -109.36\n",
      "Episode 268\tAverage Score: -99.993\n",
      "Environment solved in 268 episodes!\tAverage Score: -99.99\n",
      "0:01:32.278035\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "avg_rewards = []\n",
    "begin_time = datetime.datetime.now()\n",
    "\n",
    "agent = TutorialAgent(state_size=state_shape,action_size = action_shape,type=2,seed = 0)\n",
    "dqn(policy = \"softmax\")\n",
    "\n",
    "time_taken = datetime.datetime.now() - begin_time\n",
    "\n",
    "#evaluation criteria\n",
    "print(time_taken)\n",
    "plt.plot(np.arange(0, len(avg_rewards), 1), avg_rewards)\n",
    "plt.title(\"Average Reward vs episodes, policy: softmax\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
